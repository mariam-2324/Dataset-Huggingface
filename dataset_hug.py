# -*- coding: utf-8 -*-
"""Dataset.Hug.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yCTY51LNH_WmmhVJXo-gCTHD8cLxfIpc

# **WORKING ON DATASET FROM HUGGINGFACE**ğŸ§ 
This dataset is **initial ChatGPT-Prompt**, converted into complete Python code to load the dataset in the CSV file, and display both the head and tail of the dataset using pandas:ğŸ“Œ

## **Objective** ğŸ”
To load and explore the awesome-chatgpt-prompts dataset hosted on the Hugging Face Hub, using two different approaches:

* Any datasets can be fetched by two approaches.
1. First method is by Dataset Library of Huggingface itself.
2. Second is by Huggingface Hub Library.

## âœ…**Method 1:** from datasets import load_dataset
ğŸ§ª This is the preferred way if the dataset is properly formatted and published on Hugging Face as a Dataset repo (not just raw files like .csv, .json, etc).

ğŸ”¹ Step 1: Installing the Dataset library
"""

!pip install datasets

"""ğŸ”¹ Step 2: Importing the module "load_dataset"from the library."""

from datasets import load_dataset

ds = load_dataset("fka/awesome-chatgpt-prompts")

"""ğŸ”¹ **Step 3:** *Use df.head() and df.tail()*"""

ds['train'].to_pandas().head()

ds['train'].to_pandas().tail()

print(ds['train'][0])

"""## âœ…**Method 2:**
## ğŸ”huggingface_hub Library

### ğŸ”¹**Step 1:** Installing the Huggingface Hub Library
"""

!pip install huggingface_hub

"""## ğŸ”¹**Step 2:** Upgrading the Library"""

!pip install --upgrade huggingface_hub

"""##ğŸ”¹**Step 3:** getting Authentication to get this dataset from Huggingface Library"""

!hf auth login

"""## ğŸ”¹**Step 4:** Importing Module Login"""

from huggingface_hub import login
login()

"""### **ğŸ”¹Step 4:** Loading Dataset from Huggingface_hub
1.   Showing first few lines of the dataset by .head function
2.   Showing last few lines of the dataset by .tail function.


"""

from datasets import load_dataset

# Load dataset from Hugging Face
dataset = load_dataset("fka/awesome-chatgpt-prompts")

# Show the first and last few examples
print("----- HEAD (First 5 rows) -----")
print(dataset["train"].to_pandas().head())

print("\n----- TAIL (Last 5 rows) -----")
print(dataset["train"].to_pandas().tail())

"""## **SUMMARY:**ğŸ“
*   To load and explore the awesome-chatgpt-prompts dataset hosted on the  Hugging Face Hub, using two different approaches:

1. Method 1: Using the datasets library

2. Method 2: Using both huggingface_hub and datasets libraries (with optional authentication)

### **KEY TAKEAWAYS OF METHOD 1**âš¡
Using **datasets Library** (Simplest & Recommended)

### Description ğŸ“Œ
* load_dataset(...): Loads the dataset directly from Hugging Face.

* ds['train']: Refers to the "train" split of the dataset (this dataset has only one split).

* .to_pandas(): Converts the Hugging Face dataset to a pandas DataFrame for easier manipulation.

* .head() / .tail(): Displays the first and last 5 rows respectively.

* ds['train'][0]: Prints the very first data sample (a dictionary with fields like act, prompt, etc.).

### **KEY TAKEAWAYS OF METHOD 2**âš¡
Using **huggingface_hub + datasets Library** (With Authentication)

### Description ğŸ“Œ
* This method optionally includes authentication, which is only needed if you're accessing:

* Private or gated repositories

* Datasets with restricted access

* Once authenticated, the process to load and explore the dataset is the same as in Method 1.



### References ğŸ”—
* ğŸ“š Hugging Face Datasets Docs:

  https://huggingface.co/docs/datasets

* ğŸ“š Hugging Face Hub Docs (login, authentication):
  
  https://huggingface.co/docs/huggingface_hub

* ğŸ“ Dataset Link:

  https://huggingface.co/datasets/fka/awesome-chatgpt-prompts

"""

